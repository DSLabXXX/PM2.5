import tensorflow as tf
from tensorflow.python.ops import tensor_array_ops, control_flow_ops


class Generator(object):
    def __init__(self, num_emb_1, num_emb_2, batch_size, hidden_dim_1, hidden_dim_2,
                 sequence_length_1, sequence_length_2, start_token,
                 learning_rate=0.01, reward_gamma=0.95):
        self.embed_dim_1 = num_emb_1  # size of input vector of the first layer(embedding layer)
        self.embed_dim_2 = 1  # size of input vector of the second layer(generator layer), should equal to  output size
        self.emb_vec_dim = num_emb_2  # output size of first layer
        self.batch_size = batch_size
        self.hidden_dim_1 = hidden_dim_1
        self.hidden_dim_2 = hidden_dim_2
        self.sequence_length_1 = sequence_length_1
        self.sequence_length_2 = sequence_length_2
        self.output_size = 1
        self.start_token = tf.constant(start_token, shape=[self.batch_size, self.output_size], dtype=tf.float32)
        self.learning_rate = tf.Variable(float(learning_rate), trainable=False)
        # self.reward_gamma = reward_gamma
        self.g_params = []
        # self.temperature = 1.0
        self.grad_clip = 5.0

        self.expected_reward = tf.Variable(tf.zeros([self.sequence_length_2]))

        with tf.variable_scope('generator'):
            # maps h_tm1 to h_t for generator
            self.g_recurrent_unit_1 = self.create_recurrent_unit_1(self.g_params)
            self.g_recurrent_unit_2 = self.create_recurrent_unit_2(self.g_params)

            # maps h_t to o_t (output token logits)
            self.g_output_unit_1 = self.create_output_unit_1(self.g_params)
        self.g_output_unit_2 = self.create_output_unit_2(self.g_params)
        #
        # placeholder definition
        # ----------------------------------------------------------------------------
        # input of embedding layer(first layer of generator)
        self.raw_x = tf.placeholder(tf.float32, shape=[self.batch_size, self.sequence_length_1, self.embed_dim_1])
        # sequence of tokens generated by generator; input of discriminator
        self.x = tf.placeholder(tf.float32, shape=[self.batch_size, self.sequence_length_2, self.output_size])
        # get from rollout policy and discriminator
        self.rewards = tf.placeholder(tf.float32, shape=[self.batch_size, self.sequence_length_2])

        #
        # processed for batch
        # ----------------------------------------------------------------------------
        with tf.device("/cpu:0"):
            # dim(self.processed_x) =  (seq_length, batch_size, embed_dim)
            self.processed_x = tf.transpose(self.x, perm=[1, 0, 2])

        #
        # Initial states
        # ----------------------------------------------------------------------------
        self.h1_0 = tf.zeros([self.batch_size, self.hidden_dim_1])
        self.h1_0 = tf.stack([self.h1_0, self.h1_0])

        self.h2_0 = tf.zeros([self.batch_size, self.hidden_dim_2])
        self.h2_0 = tf.stack([self.h2_0, self.h2_0])

        #
        # generator on initial randomness
        # ----------------------------------------------------------------------------
        gen_o = tensor_array_ops.TensorArray(dtype=tf.float32, size=self.sequence_length_2,
                                             dynamic_size=False, infer_shape=True)
        # ----------------------------------------------------------------------------

        def _e_recurrence(i, x_t, h_tm1):
            h_t = self.g_recurrent_unit_1(x_t[:, i, :], h_tm1)

            return i + 1, x_t, h_t

        _, _, embed_vec = control_flow_ops.while_loop(
            cond=lambda i, _1, _2: i < self.sequence_length_1,
            body=_e_recurrence,  # layer 1: embedding layer
            loop_vars=(tf.constant(0, dtype=tf.int32), self.raw_x, self.h1_0))

        embed_vec = self.g_output_unit_1(embed_vec)
        self.embed_vec = embed_vec

        #
        # Forward prediction to predict the sequence from (t+1) to T (predict by prediction)
        # ----------------------------------------------------------------------------
        def _g_recurrence(i, x_t, embed_vec, h_tm1, gen_o):
            # Def:
            #   LSTM forward operation unit, where output at (t-1) will be sent as input at t
            #   This function is used prediction time slice from (t+1) to T
            # Args ------------
            #   i: counter
            #   x_t: input at time t
            #   h_tm1: a tensor that packs [prev_hidden_state, prev_c], i.e., h_{t-1}
            #   gen_o:
            #   gen_x: to record each predicted input from t to T
            # Returns ------------
            #   i + 1: next counter
            #   x_tp1: input at time (t+1), i.e., x_{t+1}, which is from next_token, the output from o_t
            #   h_t: a tensor that packs [now_hidden_state, now_c], i.e., h_{t}
            #   gen_o:
            #   gen_x: add next_token to the list, i.e., to record each predicted input from (t+1) to T

            # hidden_memory_tuple
            # h_tm1: the previous tensor that packs [prev_hidden_state, prev_c]
            # h_t: the current tensor that packs [now_hidden_state, now_c]
            h_t = self.g_recurrent_unit_2(tf.concat([x_t, embed_vec], 1), h_tm1)

            # dim(o_t) = (batch_size, num_emb), logits not prob
            # h_t: the current tensor that packs [now_hidden_state, now_c]
            # o_t: the output of LSTM at time t
            o_t = self.g_output_unit_2(h_t)

            x_tp1 = o_t

            # o_t = tf.multinomial(o_t, 1)
            o_t = tf.reshape(o_t, [self.batch_size])

            # [indices, batch_size]
            gen_o = gen_o.write(i, o_t)

            return i + 1, x_tp1, embed_vec, h_t, gen_o

        _, _, _, _, self.gen_o = control_flow_ops.while_loop(
            cond=lambda i, _1, _2, _3, _4: i < self.sequence_length_2,
            body=_g_recurrence,  # forward prediction
            loop_vars=(tf.constant(0, dtype=tf.int32),
                       self.start_token, embed_vec,
                       self.h2_0, gen_o))

        # dim(self.gen_x) = (seq_length, batch_size)
        self.gen_o = self.gen_o.stack()

        # dim(self.gen_x) = (batch_size, seq_length)
        self.gen_o = tf.transpose(self.gen_o, perm=[1, 0])

        # supervised pre-training for generator
        g_predictions = tensor_array_ops.TensorArray(dtype=tf.float32,
                                                     size=self.sequence_length_2,
                                                     dynamic_size=False,
                                                     infer_shape=True)

        #
        # Forward prediction to predict the sequence from 0 to t (predict by known instances)
        # ----------------------------------------------------------------------------
        # The input from 0 to t
        ta_emb_x = tensor_array_ops.TensorArray(dtype=tf.float32,
                                                size=self.sequence_length_2)
        ta_emb_x = ta_emb_x.unstack(self.processed_x)

        def _pretrain_recurrence(i, x_t, embed_vec, h_tm1, g_predictions):
            # Def:
            #   LSTM forward operation unit, given input and output
            #   This function is used prediction time slice from 1 to t
            # Args ------------
            #   i: counter
            #   x_t: input at time t
            #   h_tm1: a tensor that packs [prev_hidden_state, prev_c], i.e., h_{t-1}
            #   g_predictions: add softmax(o_t) to the list, i.e., to record each predicted input from t to T
            # Returns ------------
            #   i + 1: next counter
            #   x_tp1: input at time (t+1), i.e., x_{t+1}, which is read from ta_emb_x
            #   h_t: a tensor that packs [now_hidden_state, now_c], i.e., h_{t}
            #   g_predictions: add softmax(o_t) to the list, i.e., to record each predicted input from t to T

            #   h_tm1: the previous tensor that packs [prev_hidden_state, prev_c]
            #   h_t: the current tensor that packs [now_hidden_state, now_c]
            h_t = self.g_recurrent_unit_2(tf.concat([x_t, embed_vec], 1), h_tm1)

            # LSTM output
            # h_t: the current tensor that packs [now_hidden_state, now_c]
            # o_t: the output of LSTM at time t
            o_t = self.g_output_unit_2(h_t)

            # batch x vocab_size
            g_predictions = g_predictions.write(i, o_t)

            x_tp1 = ta_emb_x.read(i)
            return i + 1, x_tp1, embed_vec, h_t, g_predictions

        _, _, _, _, self.g_predictions = control_flow_ops.while_loop(
            cond=lambda i, _1, _2, _3, _4: i < self.sequence_length_2,
            body=_pretrain_recurrence,  # forward prediction
            loop_vars=(tf.constant(0, dtype=tf.int32),
                       self.start_token, embed_vec,
                       self.h2_0, g_predictions))
        # dim(self.g_predictions) = (batch_size, seq_length, vocab_size)
        self.g_predictions = tf.transpose(self.g_predictions.stack(), perm=[1, 0, 2])

        #
        # Pre-training loss: between generated samples and oracle data
        # ----------------------------------------------------------------------------
        # dim(tf.reduce_sum(self.x * self.g_predictions)) = (1,)
        self.pretrain_loss = -tf.reduce_sum(self.x * self.g_predictions) / (self.sequence_length_2 * self.batch_size)

        #
        # Training updates
        # ----------------------------------------------------------------------------
        pretrain_opt = self.g_optimizer(self.learning_rate)

        # Compute the gradient by using self.pretrain_loss and self.g_params
        # Clip the gradient to a finite range self.grad_clip
        self.pretrain_grad, _ = tf.clip_by_global_norm(tf.gradients(self.pretrain_loss, self.g_params), self.grad_clip)

        # Update parameters by using self.pretrain_grad and self.g_params
        self.pretrain_updates = pretrain_opt.apply_gradients(zip(self.pretrain_grad, self.g_params))

        #
        # Unsupervised Training
        # ----------------------------------------------------------------------------
        # dim(tf.reduce_sum(self.x * g_predictions, 1)) = (len(self.x),)
        self.g_loss = -tf.reduce_sum(tf.reduce_sum(self.x * self.g_predictions, 1) * tf.reshape(self.rewards, [-1]))

        # Set the optimizer (default is AdamOptimizer)
        g_opt = self.g_optimizer(self.learning_rate)

        # Compute the gradient by using self.g_loss and self.g_params
        # Clip the gradient to a finite range self.grad_clip
        self.g_grad, _ = tf.clip_by_global_norm(tf.gradients(self.g_loss, self.g_params), self.grad_clip)

        # Update parameters by using self.g_grad and self.g_params
        self.g_updates = g_opt.apply_gradients(zip(self.g_grad, self.g_params))

    def generate(self, sess, raw_x):
        outputs = sess.run(self.gen_o, feed_dict={self.raw_x: raw_x})
        return outputs

    def pretrain_step(self, sess, raw_x, x):
        outputs = sess.run([self.pretrain_updates, self.pretrain_loss], feed_dict={self.raw_x: raw_x, self.x: x})
        return outputs

    def init_matrix(self, shape):
        return tf.random_normal(shape, stddev=0.1)

    def init_vector(self, shape):
        return tf.zeros(shape)

    def create_recurrent_unit_1(self, params):
        # Define Weights and Bias for input and hidden tensor
        self.Wi_1 = tf.Variable(self.init_matrix([self.embed_dim_1, self.hidden_dim_1]))
        self.Ui_1 = tf.Variable(self.init_matrix([self.hidden_dim_1, self.hidden_dim_1]))
        self.bi_1 = tf.Variable(self.init_matrix([self.hidden_dim_1]))

        self.Wf_1 = tf.Variable(self.init_matrix([self.embed_dim_1, self.hidden_dim_1]))
        self.Uf_1 = tf.Variable(self.init_matrix([self.hidden_dim_1, self.hidden_dim_1]))
        self.bf_1 = tf.Variable(self.init_matrix([self.hidden_dim_1]))

        self.Wog_1 = tf.Variable(self.init_matrix([self.embed_dim_1, self.hidden_dim_1]))
        self.Uog_1 = tf.Variable(self.init_matrix([self.hidden_dim_1, self.hidden_dim_1]))
        self.bog_1 = tf.Variable(self.init_matrix([self.hidden_dim_1]))

        self.Wc_1 = tf.Variable(self.init_matrix([self.embed_dim_1, self.hidden_dim_1]))
        self.Uc_1 = tf.Variable(self.init_matrix([self.hidden_dim_1, self.hidden_dim_1]))
        self.bc_1 = tf.Variable(self.init_matrix([self.hidden_dim_1]))

        params.extend([self.Wi_1, self.Ui_1, self.bi_1,
                       self.Wf_1, self.Uf_1, self.bf_1,
                       self.Wog_1, self.Uog_1, self.bog_1,
                       self.Wc_1, self.Uc_1, self.bc_1])

        def unit(x, hidden_memory_tm1):
            #
            # Define LSTM transition operation
            # Args:
            #   x: input
            #   hidden_memory_tm1: the previous tensor that packs [prev_hidden_state, prev_c]
            # Returns:
            #   a current tensor that packs [now_hidden_state, now_c]

            previous_hidden_state, c_prev = tf.unstack(hidden_memory_tm1)

            # Input Gate
            i = tf.sigmoid(tf.matmul(x, self.Wi_1) +
                           tf.matmul(previous_hidden_state, self.Ui_1) + self.bi_1)

            # Forget Gate
            f = tf.sigmoid(tf.matmul(x, self.Wf_1) +
                           tf.matmul(previous_hidden_state, self.Uf_1) + self.bf_1)

            # Output Gate
            o = tf.sigmoid(tf.matmul(x, self.Wog_1) +
                           tf.matmul(previous_hidden_state, self.Uog_1) + self.bog_1)

            # New Memory Cell
            c_ = tf.nn.tanh(tf.matmul(x, self.Wc_1) +
                            tf.matmul(previous_hidden_state, self.Uc_1) + self.bc_1)

            # Final Memory cell
            c = f * c_prev + i * c_

            # Current Hidden state
            current_hidden_state = o * tf.nn.tanh(c)

            return tf.stack([current_hidden_state, c])

        return unit

    def create_output_unit_1(self, params):
        self.Wo_1 = tf.Variable(self.init_matrix([self.hidden_dim_1, self.emb_vec_dim]))
        self.bo_1 = tf.Variable(self.init_matrix([self.emb_vec_dim]))
        params.extend([self.Wo_1, self.bo_1])

        def unit(hidden_memory_tuple):
            #
            # Define LSTM output operation
            # Args:
            #   hidden_memory_tuple: a tensor that packs [now_hidden_state, now_c]
            # Returns:
            #   logits: the output of LSTM at time t
            hidden_state, c_prev = tf.unstack(hidden_memory_tuple)

            # hidden_state : batch x hidden_dim
            logits = tf.matmul(hidden_state, self.Wo_1) + self.bo_1

            # output = tf.nn.softmax(logits)
            return logits

        return unit

    def create_recurrent_unit_2(self, params):
        # Define Weights and Bias for input and hidden tensor
        self.Wi_2 = tf.Variable(self.init_matrix([(self.embed_dim_2+self.emb_vec_dim), self.hidden_dim_2]))
        self.Ui_2 = tf.Variable(self.init_matrix([self.hidden_dim_2, self.hidden_dim_2]))
        self.bi_2 = tf.Variable(self.init_matrix([self.hidden_dim_2]))

        self.Wf_2 = tf.Variable(self.init_matrix([(self.embed_dim_2+self.emb_vec_dim), self.hidden_dim_2]))
        self.Uf_2 = tf.Variable(self.init_matrix([self.hidden_dim_2, self.hidden_dim_2]))
        self.bf_2 = tf.Variable(self.init_matrix([self.hidden_dim_2]))

        self.Wog_2 = tf.Variable(self.init_matrix([(self.embed_dim_2+self.emb_vec_dim), self.hidden_dim_2]))
        self.Uog_2 = tf.Variable(self.init_matrix([self.hidden_dim_2, self.hidden_dim_2]))
        self.bog_2 = tf.Variable(self.init_matrix([self.hidden_dim_2]))

        self.Wc_2 = tf.Variable(self.init_matrix([(self.embed_dim_2+self.emb_vec_dim), self.hidden_dim_2]))
        self.Uc_2 = tf.Variable(self.init_matrix([self.hidden_dim_2, self.hidden_dim_2]))
        self.bc_2 = tf.Variable(self.init_matrix([self.hidden_dim_2]))

        params.extend([self.Wi_2, self.Ui_2, self.bi_2,
                       self.Wf_2, self.Uf_2, self.bf_2,
                       self.Wog_2, self.Uog_2, self.bog_2,
                       self.Wc_2, self.Uc_2, self.bc_2])

        def unit(x, hidden_memory_tm1):
            previous_hidden_state, c_prev = tf.unstack(hidden_memory_tm1)
            i = tf.sigmoid(tf.matmul(x, self.Wi_2) +
                           tf.matmul(previous_hidden_state, self.Ui_2) + self.bi_2)
            f = tf.sigmoid(tf.matmul(x, self.Wf_2) +
                           tf.matmul(previous_hidden_state, self.Uf_2) + self.bf_2)
            o = tf.sigmoid(tf.matmul(x, self.Wog_2) +
                           tf.matmul(previous_hidden_state, self.Uog_2) + self.bog_2)
            c_ = tf.nn.tanh(tf.matmul(x, self.Wc_2) +
                            tf.matmul(previous_hidden_state, self.Uc_2) + self.bc_2)
            c = f * c_prev + i * c_
            current_hidden_state = o * tf.nn.tanh(c)
            return tf.stack([current_hidden_state, c])
        return unit

    def create_output_unit_2(self, params):
        self.Wo_2 = tf.Variable(self.init_matrix([self.hidden_dim_2, self.output_size]))
        self.bo_2 = tf.Variable(self.init_matrix([self.output_size]))
        params.extend([self.Wo_2, self.bo_2])

        def unit(hidden_memory_tuple):
            #
            # Define LSTM output operation
            # Args:
            #   hidden_memory_tuple: a tensor that packs [now_hidden_state, now_c]
            # Returns:
            #   logits: the output of LSTM at time t
            hidden_state, c_prev = tf.unstack(hidden_memory_tuple)

            # hidden_state : batch x hidden_dim
            logits = tf.matmul(hidden_state, self.Wo_2) + self.bo_2

            # output = tf.nn.softmax(logits)
            return logits

        return unit

    def g_optimizer(self, str_type, *args, **kwargs):
        return tf.train.AdamOptimizer(*args, **kwargs)
        # return tf.train.RMSPropOptimizer(*args, **kwargs)
